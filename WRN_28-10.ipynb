{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:09:39.207434Z","iopub.status.busy":"2024-08-17T22:09:39.206716Z","iopub.status.idle":"2024-08-17T22:09:57.673177Z","shell.execute_reply":"2024-08-17T22:09:57.672301Z","shell.execute_reply.started":"2024-08-17T22:09:39.207402Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchsummary in /Users/parkyunsu/anaconda3/envs/yg3/lib/python3.12/site-packages (1.5.1)\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","!pip install torchsummary\n","from torchsummary import summary\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","import os\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:09:57.675374Z","iopub.status.busy":"2024-08-17T22:09:57.674807Z","iopub.status.idle":"2024-08-17T22:09:57.684401Z","shell.execute_reply":"2024-08-17T22:09:57.683382Z","shell.execute_reply.started":"2024-08-17T22:09:57.675346Z"},"trusted":true},"outputs":[],"source":["class Basicblock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride, dropRate):\n","        super(Basicblock, self).__init__()\n","        self.residual = nn.Sequential(\n","            nn.BatchNorm2d(in_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        )\n","        self.droprate = dropRate\n","        self.skip = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels:\n","            self.skip = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","            \n","    def forward(self, x):\n","        identity =  x\n","        x = self.residual(x)\n","        if self.droprate > 0:\n","            x = F.dropout(x, p=self.droprate, training=self.training)\n","        x += self.skip(identity)\n","        return x"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:09:57.685860Z","iopub.status.busy":"2024-08-17T22:09:57.685588Z","iopub.status.idle":"2024-08-17T22:09:57.699707Z","shell.execute_reply":"2024-08-17T22:09:57.698760Z","shell.execute_reply.started":"2024-08-17T22:09:57.685833Z"},"trusted":true},"outputs":[],"source":["class WideResNet(nn.Module):\n","    def __init__(self, depth, widen_factor, num_classes, dropRate):\n","        super(WideResNet, self).__init__()\n","        self.in_channels = 16\n","\n","        assert ((depth-4)%6 == 0)\n","        n = (depth-4) // 6\n","        k = widen_factor\n","#         print('|Wide-Resnet %dx%d' %(depth, k))\n","        nStages = [16, 16*k, 32*k, 64*k]\n","\n","        self.conv1 = nn.Conv2d(3,nStages[0], kernel_size=3, stride=1, padding=1, bias=False)\n","        self.layer1 = self._wide_layer(Basicblock, nStages[1], n, stride=1, dropRate=dropRate)\n","        self.layer2 = self._wide_layer(Basicblock, nStages[2], n, stride=2, dropRate=dropRate)\n","        self.layer3 = self._wide_layer(Basicblock, nStages[3], n, stride=2, dropRate=dropRate)\n","        self.bn1 = nn.BatchNorm2d(nStages[3])\n","        self.relu = nn.ReLU()\n","        self.fc = nn.Linear(nStages[3], num_classes)\n","        self.nStages = nStages[3]\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","            elif isinstance(m, nn.Linear):\n","                m.bias.data.zero_()\n","\n","    def _wide_layer(self, block, out_channels, num_blocks, stride, dropRate):\n","        strides = [stride] + [1] * (int(num_blocks) - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_channels, out_channels, stride, dropRate))\n","            self.in_channels = out_channels\n","\n","        return nn.Sequential(*layers)\n","    \n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.relu(self.bn1(x))\n","        x = F.avg_pool2d(x, 8)\n","        x = x.view(-1, self.nStages)\n","        return self.fc(x)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:09:57.702062Z","iopub.status.busy":"2024-08-17T22:09:57.701698Z","iopub.status.idle":"2024-08-17T22:09:58.669653Z","shell.execute_reply":"2024-08-17T22:09:58.668611Z","shell.execute_reply.started":"2024-08-17T22:09:57.702039Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Output shape: torch.Size([1, 10])\n","Output: tensor([[-0.0181,  0.3184, -0.0957,  0.0275, -0.6190, -0.3128, -0.4456,  0.0905,\n","          0.3843, -0.3158]], grad_fn=<AddmmBackward0>)\n"]}],"source":["model1 = WideResNet(28, 10, 10, 0.3)\n","random_input = torch.randn(1, 3, 32, 32)\n","\n","# Pass the random input through the model\n","output = model1(random_input)\n","\n","# Print the output\n","print(\"Output shape:\", output.shape)\n","print(\"Output:\", output)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:09:59.531792Z","iopub.status.busy":"2024-08-17T22:09:59.531372Z","iopub.status.idle":"2024-08-17T22:10:06.522072Z","shell.execute_reply":"2024-08-17T22:10:06.521289Z","shell.execute_reply.started":"2024-08-17T22:09:59.531759Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["path = '/Users/parkyunsu/gitfile/WideResNet/data'\n","if not os.path.exists(path):\n","    os.mkdir(path)\n","\n","# 데이터셋 전처리\n","transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),  # 수평으로 뒤집기\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","])\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","])\n","\n","\n","# CIFAR-10\n","trainset = datasets.CIFAR10(root=path, train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n","\n","testset = datasets.CIFAR10(root=path, train=False, download=True, transform=test_transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:10:06.524142Z","iopub.status.busy":"2024-08-17T22:10:06.523788Z","iopub.status.idle":"2024-08-17T22:10:06.533414Z","shell.execute_reply":"2024-08-17T22:10:06.532615Z","shell.execute_reply.started":"2024-08-17T22:10:06.524109Z"},"trusted":true},"outputs":[],"source":["# MPS 또는 CPU 설정\n","device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n","\n","# 모델을 MPS 또는 CPU로 이동\n","model1.to(device)\n","\n","# hyper parameters\n","initial_learning_rate = 0.1\n","\n","# loss, optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model1.parameters(), lr=initial_learning_rate, momentum=0.9, weight_decay=0.0005)\n","\n","# scheduler\n","scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120], gamma=0.1)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:10:06.535138Z","iopub.status.busy":"2024-08-17T22:10:06.534867Z","iopub.status.idle":"2024-08-17T22:10:06.549469Z","shell.execute_reply":"2024-08-17T22:10:06.548436Z","shell.execute_reply.started":"2024-08-17T22:10:06.535117Z"},"trusted":true},"outputs":[],"source":["def model_train(model1, data_loader, criterion, optimizer, epoch):\n","    model1.train()\n","\n","    global epoch_step\n","    running_size, running_loss, correct = 0.0, 0.0, 0.0\n","\n","    if (epoch + 1) % epoch_step == 0 or epoch == 0:\n","        pbar = tqdm(data_loader)\n","    else:\n","        pbar = data_loader\n","\n","    for images, labels in pbar:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model1(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * images.size(0)\n","        running_size += images.size(0)\n","        correct += (outputs.argmax(1) == labels).sum().item()\n","\n","        if (epoch + 1) % epoch_step == 0 or epoch == 0:\n","            pbar.set_description('[Training] loss: ' +\n","                                f'{running_loss / running_size:.4f}, accuracy: ' +\n","                                f'{correct / running_size:.4f}')\n","        del images, labels, outputs, loss\n","        torch.mps.empty_cache()\n","        \n","    avg_accuracy = correct / running_size\n","    avg_loss = running_loss / running_size\n","    \n","    # Train Error Rate 계산\n","    train_error_rate = 100 * (1 - avg_accuracy)\n","    \n","    # Train Error Rate 출력 (epoch_step에 따라)\n","    if (epoch + 1) % epoch_step == 0 or epoch == 0:\n","        print(f'Train Error Rate: {train_error_rate:.2f}%')\n","\n","    return avg_loss, avg_accuracy, train_error_rate\n","\n","def model_eval(model1, data_loader, criterion, epoch):\n","    model1.eval()\n","    with torch.no_grad():\n","        running_loss, correct = 0.0, 0.0\n","\n","        if (epoch + 1) % epoch_step == 0 or epoch == 0:\n","            pbar = tqdm(data_loader)\n","        else:\n","            pbar = data_loader\n","\n","        for images, labels in pbar:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model1(images)\n","            pred = outputs.argmax(dim=1)\n","\n","            correct += torch.sum(pred == labels).item()\n","            running_loss += criterion(outputs, labels).item() * images.size(0)\n","\n","        accuracy = correct / len(data_loader.dataset)\n","        loss = running_loss / len(data_loader.dataset)\n","        \n","        # Test Error Rate 계산\n","        test_error_rate = 100 * (1 - accuracy)\n","        \n","        # Test Error Rate 출력 (epoch_step에 따라)\n","        if (epoch + 1) % epoch_step == 0 or epoch == 0:\n","            print(f'Test Error Rate: {test_error_rate:.2f}%')\n","        \n","        return loss, accuracy, test_error_rate"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:10:06.552463Z","iopub.status.busy":"2024-08-17T22:10:06.552192Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[Training] loss: 1.9558, accuracy: 0.2656:  29%|██▊       | 112/391 [04:00<09:58,  2.15s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m epoch_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 7\u001b[0m     train_loss, train_accuracy, train_error_rate \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     test_loss, test_accuracy, test_error_rate \u001b[38;5;241m=\u001b[39m model_eval(model1, testloader, criterion, epoch)\n\u001b[1;32m     10\u001b[0m     loss\u001b[38;5;241m.\u001b[39mappend([train_loss, test_loss])\n","Cell \u001b[0;32mIn[7], line 20\u001b[0m, in \u001b[0;36mmodel_train\u001b[0;34m(model1, data_loader, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 20\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m running_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     22\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (outputs\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# 모델 학습 및 평가 코드\n","loss, accuracy, train_error_rates, test_error_rates = [], [], [], []\n","num_epochs = 200\n","epoch_step = 20\n","\n","for epoch in range(num_epochs):\n","    train_loss, train_accuracy, train_error_rate = model_train(model1, trainloader, criterion, optimizer, epoch)\n","    test_loss, test_accuracy, test_error_rate = model_eval(model1, testloader, criterion, epoch)\n","\n","    loss.append([train_loss, test_loss])\n","    accuracy.append([train_accuracy, test_accuracy])\n","    train_error_rates.append(train_error_rate)\n","    test_error_rates.append(test_error_rate)\n","\n","    scheduler.step()  # 스케줄러 업데이트\n","\n","    if (epoch + 1) % epoch_step == 0 or epoch == 0:\n","        print(f\"epoch {epoch+1:03d}, Training loss: \" + \n","              f\"{train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n","        print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")\n","        print(f\"Train error rate: {train_error_rate:.2f}%, Test error rate: {test_error_rate:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train Error Rate와 Test Error Rate 그림 그리기\n","plt.figure(figsize=(10, 5))\n","plt.plot(range(1, num_epochs + 1), train_error_rates, label='Train Error Rate')\n","plt.plot(range(1, num_epochs + 1), test_error_rates, label='Test Error Rate')\n","plt.xlabel('Epoch')\n","plt.ylabel('Error Rate (%)')\n","plt.title('Train and Test Error Rate Over Epochs')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# 손실 그래프\n","train_losses, val_losses = zip(*loss)\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(train_losses, label='train')\n","plt.plot(val_losses, label='val')\n","plt.xlabel('Training Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.title('Train-Val Loss')\n","\n","# 정확도 그래프\n","train_accuracies, val_accuracies = zip(*accuracy)\n","plt.subplot(1, 2, 2)\n","plt.plot(train_accuracies, label='train')\n","plt.plot(val_accuracies, label='val')\n","plt.xlabel('Training Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.title('Train-Val Accuracy')\n","\n","plt.tight_layout()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["min_train_error_rate = min(train_error_rates)\n","min_test_error_rate = min(test_error_rates)\n","\n","# 최소값 출력\n","print(f\"Minimum Train Error Rate: {min_train_error_rate:.2f}%\")\n","print(f\"Minimum Test Error Rate: {min_test_error_rate:.2f}%\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30746,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
